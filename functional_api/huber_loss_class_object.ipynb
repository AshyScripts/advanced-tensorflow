{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e87149b2-6188-4c9a-9e54-3589b0073cf1",
   "metadata": {},
   "source": [
    "# Huber Loss hyperparameter and class\n",
    "\n",
    "We'll extend our previous Huber loss function and show how you can include hyperparameters in defining loss functions. We'll also look at how to implement a custom loss as an object by inheriting the [Loss](https://www.tensorflow.org/api_docs/python/tf/keras/losses/Loss) class."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4cedbb-b518-4000-9982-d3c91f9959f1",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e17c3b41-02d4-4e64-942e-4a0bcc3bb75c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c14cf30-00b3-46f7-8a23-e99e663cb684",
   "metadata": {},
   "source": [
    "## Dataset\n",
    "\n",
    "this model will be trained on the `xs` and `ys` below where the relationship is $y = 2x-1$. Thus, later, when we test for `x=10`, whichever version of the model gets the closest answer to `19` will be deemed more accurate."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "92da9e11-1338-4846-805e-4ceb80111cb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "xs = np.array([-1.0,  0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n",
    "\n",
    "# labels\n",
    "ys = np.array([-3.0, -1.0, 1.0, 3.0, 5.0, 7.0], dtype=float)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2751fc72-511a-4edd-a958-6ad4c45507f0",
   "metadata": {},
   "source": [
    "## Custom loss with hyperparameter\n",
    "\n",
    "The `loss` argument in `model.compile()` only accepts functions that accepts two parameters: the ground truth (`y_true`) and the model predictions (`y_pred`). If we want to include a hyperparameter that we can tune, then we can define a wrapper function that accepts this hyperparameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2597797a-1d9e-4ccb-9f02-1524cfce112a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper function that accepts a hyperparamater\n",
    "def my_huber_loss_with_threshold(threshold):\n",
    "    def my_huber_loss(y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= threshold\n",
    "        small_error_loss = 0.5 * tf.square(error)\n",
    "        big_error_loss = threshold * (tf.abs(error) - (0.5 * threshold))\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)\n",
    "    return my_huber_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5625ec0-4735-48a6-a9c3-664193ad7466",
   "metadata": {},
   "source": [
    "> We can now specify the `loss` as the wrapper function above. Notice that we can now set the `threshold` value. Try varying this value and see the results you get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "63cc355b-5058-48d1-ae46-9da54d51d5a8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "[[18.467283]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=my_huber_loss_with_threshold(threshold=1.2))\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4dc6c90-813c-4b54-969e-5aeadd0297a0",
   "metadata": {},
   "source": [
    "## Implement Custom Loss as a Class\n",
    "\n",
    "We can also implement our custom loss as a class. It inherits from the Keras Loss class and the syntax and required methods are shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "35fc5157-9f23-45f8-b50f-5ceb719e362b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Loss class\n",
    "from tensorflow.keras.losses import Loss\n",
    "\n",
    "class MyHuberLoss(Loss):\n",
    "    # Class attributes\n",
    "    threshold = 1\n",
    "\n",
    "    # initialize instance attributes\n",
    "    def __init__(self, threshold):\n",
    "        super().__init__()\n",
    "        self.threshold = threshold\n",
    "\n",
    "    # compute loss\n",
    "    def call(self, y_true, y_pred):\n",
    "        error = y_true - y_pred\n",
    "        is_small_error = tf.abs(error) <= self.threshold\n",
    "        small_error_loss = tf.square(error) / 2\n",
    "        big_error_loss = self.threshold * (tf.abs(error) - (0.5 * self.threshold))\n",
    "        return tf.where(is_small_error, small_error_loss, big_error_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68888284-aa12-4dd2-b10e-b11e47f2e261",
   "metadata": {},
   "source": [
    "> You can specify the loss by instantiating an object from your custom loss class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "655fd70d-13a4-4f79-985b-82db2758776a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 20ms/step\n",
      "[[18.763336]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=MyHuberLoss(threshold=1.02))\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0bec96d7-5165-49dc-91cd-ce498f26ba4c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 19ms/step\n",
      "[[18.82129]]\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([keras.layers.Dense(units=1, input_shape=[1])])\n",
    "model.compile(optimizer='sgd', loss=MyHuberLoss(threshold=1.05))\n",
    "model.fit(xs, ys, epochs=500,verbose=0)\n",
    "print(model.predict([10.0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e123028-1070-4b36-be1d-3a1a3eba38f8",
   "metadata": {},
   "source": [
    "> Now we can see by using loss as a class, how we can incorporate our loss function in hypertuning stage!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34a7a990-54dc-4c30-8ac7-e77f7a697a20",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
